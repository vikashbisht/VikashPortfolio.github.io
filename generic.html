<!DOCTYPE HTML>
<!--
	Hyperspace by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>ProjectsbyVikashBisht</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Header -->
			<header id="header">
				<a href="index.html" class="title">Data Analysis</a>
				<nav>
					<ul>
						<li><a href="index.html">Home</a></li>
						<li><a href="generic.html" class="active">Projects</a></li>
						<li><a href="https://github.com/noobmeister" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
						<li><a href="https://www.linkedin.com/in/vibi67/" class="icon brands fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
					</ul>
				</nav>
			</header>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<section id="main" class="wrapper">
						<div class="inner">
							<h1 class="major">Projects By Vikash Bisht</h1>
							<h2>Covid-19 Mask Detection</h2>
							<span class="image fit"><img src="images/fusion-medical-animation-rnr8D3FNUNY.jpg" alt="" /></span>
							<p>The Covid-19 Mask Detection project focuses on creating a real-time mask detection model using deep learning and transfer learning. The objective is to develop a system that can automatically identify whether a person is wearing a mask or not, which is essential for enforcing mask-wearing guidelines during the Covid-19 pandemic. The model was trained using a dataset of over 600 images, likely obtained from Kaggle. These images consisted of examples of individuals both wearing and not wearing masks, serving as the basis for the model to distinguish between the two classes.</p>
							<p>In summary, the Covid-19 Mask Detection project involved training a real-time mask detection model using deep learning and transfer learning techniques. A dataset of over 600 images, likely obtained from Kaggle, was used for training. Libraries like OpenCV and Scikit-learn played a crucial role in the implementation of the model. The resulting system can accurately identify whether individuals are wearing masks in real-time, contributing to efforts in controlling the spread of Covid-19.</p>
							<h2>Netflix Dashboard using Tableau</h2>
							<span class="image fit"><img src="images/Netflix.png" alt="" /></span>
							<p>The project was created to analyze the correlation between various variables related to Netflix using a dataset obtained from Kaggle. Insights were derived from the data to gain a better understanding of the trends within the dataset. To identify trends and patterns between different variables, a Tableau dashboard was developed, utilizing various visualizations. The visualizations helped in visually representing the relationships and dependencies within the dataset. By leveraging Tableau's features, the project aimed to provide valuable insights into the Netflix-related data and enhance understanding of the trends and patterns present.</p>
							<h2>Fabricating Dataset with Web Scrapping using Beautiful Soup</h2>
							<span class="image fit"><img src="images/web-scraping_1280x533_301.webp" alt="" /></span>
							<p>The project involved fabricating a dataset through web scraping using Beautiful Soup, a popular Python library for parsing HTML and XML data. The primary objective was to create JSON and CSV datasets from the Disney Wikipedia page for further analysis. Using Beautiful Soup's functionality, the project navigated through the HTML structure, identified relevant data, and extracted it. This data was then organized and formatted into JSON and CSV formats to create the datasets. JSON (JavaScript Object Notation) is a popular data interchange format, while CSV (Comma-Separated Values) is commonly used for tabular data representation.</p>
							<p>In summary, the project involved fabricating datasets through web scraping using Beautiful Soup. The Disney Wikipedia page was the target for data extraction, with the objective of creating JSON and CSV datasets. Beautiful Soup, along with libraries like requests and pickle, facilitated the web scraping process, allowing for the extraction, organization, and serialization of the desired data.</p>
							<h2>Other Projects By Me:</h2>
							<p></p>
						</div>
					</section>

			</div>

		<!-- Footer -->
			<footer id="footer" class="wrapper alt">
				<div class="inner">
					<ul class="menu">
						<li>&copy;Author: Vikash Bisht <a href="https://www.linkedin.com/in/vibi67/">LinkedIn</a></li><li>Other Projects: <a href="https://github.com/noobmeister/Resume_Projects">GitHub Repository</a></li><li>Image Courtesy: unsplash.com</li>
					</ul>
				</div>
			</footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>